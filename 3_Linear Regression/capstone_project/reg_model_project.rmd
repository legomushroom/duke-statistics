---
title: "Modeling and prediction for movies"
output: 
  html_document: 
    fig_height: 4
    highlight: pygments
    theme: spacelab
---

## Setup

### Load packages

```{r load-packages, message = FALSE}
library(ggplot2)
library(dplyr)
library(statsr)
install.packages("GGally")
library(GGally)
```

### Load data

Make sure your data and R Markdown files are in the same directory. When loaded
your data file will be called `movies`. Delete this note when before you submit your work. 

```{r load-data}
load("movies.rdata")
```

* * *

## Part 1: Data

From the description of the data in the codebook file we can see that the data set is comprised of 651 randomly sampled movies produced and released before 2016. Random sample implies that the data could indeed be generalized to all movies released before 2016. The population of interest is unknown, so we will assume that the data could be generalized to all US movies in the specified time range.
Let's inspect time range in the sample intself:

```{r}
summary(movies$thtr_rel_year)
```

As we can see from the sample statistics over the `thtr_rel_year` variable, the actual range is in between `1970` - `2014`, so since there is no movies beyond 2014 in the sample, and since using a linear regression model that we will build on data that is beyond observed data will imply `extrapolation`, we will shrink the range and say that: "These data sample is generalizable to all US movies that were released between 1970 and 2014 inclusive".

This is an observational study, so no random assignment was used so we cannot do any causal conclusions.

* * *

## Part 2: Research question

1. Do the movies that have a good rating at `Rotten Tomatoes` resource expected to also have a good rating at `IMDB`?

The question is of interest to the author since when he searches for a movie to watch, he has to read the rating on both `IMDB` and `Rotten Tomatoes` resources. Knowing a relation between rating of the two sites and by building a linear regression model, the author can potentially save a lot of time by using the model to predict expected rating on the `IMDB` resource by reading the ratings on the `Rotten Tomatoes` website, instead of reading thru both.

* * *

## Part 3: Exploratory data analysis

Let's do an exploratory data analysis to see what the data we are working with.

### IMDB Rating

Let's explore the `imdb_rating` variable first.

```{r}
summary(movies$imdb_rating)
str(movies$imdb_rating)
```

As we can see, the `imdb_rating` is `numerical` that is rounded to one decimal place. While the `IMDB` site has the `1-10` rating range, there is no rating in the sample over `9` which might be observed simply by chance. Also since the `median` is very close to `mean` we expect the distribution not to be very skewed (but still skewed), since the `mean` is smaller than the `median` we expect to see a lower tail skew(the left longer tails, pulls mean of the distribution to the left thus the skew is observed).

Let's see the distribution:

```{r}
ggplot(movies, aes(x = imdb_rating)) + geom_histogram(binwidth = .5)
```

The histogram confirms our assumptions - the distribution is slightly left skewed with the majority of the observations in between `5.5` to `7.75` range which means that the `IMDB` users do not tend to give a movie a very small or very high mark with preference to the higher one. Also, there seem to be not much rating scores over `8`.

### Audience Score

Let's do the same EDA for the `audience_score` variable.

```{r}
summary(movies$audience_score)
str(movies$audience_score)
```

The statistics show that this is numerical variable in between with range of `1` to `100` rounded to two decimal places. The actual min is `11` and max is `97`, looking at the computed statistics alone we can expect that the distribution is very similar to the one we had for the `imdb_rating` variable - `mean` is very close but still smaller to `median` which indicates a slight left skew. Let's build a histogram to visualize it:

```{r}
ggplot(movies, aes(x = audience_score)) + geom_histogram(binwidth = 10)
```

Our assumptions are about true, the distribution is not exactly the same - it has much longer left tail thus more spread. The majority of the observation is in between of `25` to `90`, observations on the higher end are closer to the max score than we had for the `imdb_rating` variable.

### audience_score vs imdb_rating

Let's scatterplot the variables to see if there is any correlation trend between them:

```{r}
ggplot(movies, aes(x = audience_score, y = imdb_rating)) + geom_jitter()
```

On the plot, we can see a strong positive about linear association between the variables. We can also see a tiny curvature in the data, we will need to confirm the linearity condition when we will do the model diagnostics.

The correlation could be evaluated with a single number:

```{r}
cor(movies$imdb_rating, movies$audience_score)
```

Indeed, there is a strong association between the variables.

* * *

## Part 4: Modeling


Let's see what variables could be helpful in linear regression modeling, for that we will create a matrix plot:


```{r}
# subset the `movies` data with the variables of interest
movies2 = data.frame(imdb_rating = movies$imdb_rating, best_actor_win = movies$best_actor_win, best_dir_win = movies$best_dir_win, best_actress_win = movies$best_actress_win, audience_score = movies$audience_score, runtime = movies$runtime, critics_score = movies$critics_score)

movies2 = movies2 %>% mutate(best_actor_win = ifelse(best_actor_win == 'yes', 1, 0))
movies2 = movies2 %>% mutate(best_actress_win = ifelse(best_actress_win == 'yes', 1, 0))
movies2 = movies2 %>% mutate(best_dir_win = ifelse(best_dir_win == 'yes', 1, 0))

ggpairs(movies2)
```

From the matrix plot above we can learn few lessons:

  1. `critics_score` have a large correlation value with the `imdb_rating` (0.765) but at the same time, the `critics_score` and `audience_score` are strongly associated as well. Thus using both variables for linear regression models may complicate model estimation.
  2. surprisingly, the `runtime` variable might be a significant predictor - the correlation with `imdb_rating` is `0.268` and
correlation with the `audience_score` variable is fairly weak.
  3. the `best_actress_win`, `best_actor_win` and `best_dir_win` variables have very weak association with the response variable thus might not be significant predictors.
  
We will use all of the variables above(`best_actress_win`, `best_actor_win`, `best_dir_win`, `audience_score`, `runtime` `critics_score`) for our full model to start with and see if our assumptions hold.

Let's build a linear regression model for predicting the `imdb_rating` score. Since we are interested in model performance rather than finding which variables are a significant predictor of the response variable, we will use `adjusted R^2` method. Whether we will do `forward selection` or `backward elimination` is not important for the study so we will pick the later.

```{r}
model = lm(imdb_rating ~ best_actor_win + best_dir_win + best_actress_win + audience_score + runtime + critics_score, data = movies2)

summary(model)
```

We have a large `adjusted R^2` value which evaluates the model performance. As we expected the `p-values` for the `best_actor_win`, `best_dir_win` and `best_actress_win` are much larger than the significance level of `5%` thus we'd reject the null hypothesis concluding that theese data do not provide significant evidence that each of the variables are significant predictors of the response variable, given all else hold constant. Of course, since we use the adjusted R^2 method, we will not use this insight for model optimization.

Next we will remove each variable one by one and see if absense of any of the variables gives use improvement in our `R^2` value:


```{r}
print('initial')
print(summary(model)$adj.r.squared)

m1 = lm(imdb_rating ~ best_dir_win + best_actress_win + 
    audience_score + runtime + critics_score, data = movies2)
print('best_actor_win')
print(summary(m1)$adj.r.squared)

m2 = lm(imdb_rating ~ best_actor_win + best_actress_win + 
    audience_score + runtime + critics_score, data = movies2)
print('best_dir_win')
print(summary(m2)$adj.r.squared)

m3 = lm(imdb_rating ~ best_actor_win + best_dir_win + 
    audience_score + runtime + critics_score, data = movies2)
print('best_actress_win')

m4 = lm(imdb_rating ~ best_actor_win + best_dir_win + best_actress_win + runtime + critics_score, data = movies2)
print('audience_score')
print(summary(m4)$adj.r.squared)

m5 = lm(imdb_rating ~ best_actor_win + best_dir_win + best_actress_win + 
    audience_score + critics_score, data = movies2)
print('runtime')
print(summary(m5)$adj.r.squared)

m6 = lm(imdb_rating ~ best_actor_win + best_dir_win + best_actress_win + 
    audience_score + runtime, data = movies2)
print('critics_score')
print(summary(m6)$adj.r.squared)
```

As we can see, dropping the `best_dir_win` will give us the most `adjusted R^2` gains. Next, taking the new improved `adjusted R^2` as the base value, we will need to repeat the same with variables that were not dropped, eliminating them, one by one, until the `adjusted R^2` stops improving.

```{r}
m0 = lm(imdb_rating ~ best_actor_win + best_actress_win + 
    audience_score + runtime + critics_score, data = movies2)
print('initial')
print(summary(m0)$adj.r.squared)

m1 = lm(imdb_rating ~ best_actress_win + 
    audience_score + runtime + critics_score, data = movies2)
print('best_actor_win')
print(summary(m1)$adj.r.squared)

m2 = lm(imdb_rating ~ best_actor_win + 
    audience_score + runtime + critics_score, data = movies2)
print('best_actress_win')
print(summary(m2)$adj.r.squared)

m3 = lm(imdb_rating ~ best_actor_win + best_actress_win + 
     runtime + critics_score, data = movies2)
print('audience_score')
print(summary(m3)$adj.r.squared)

m4 = lm(imdb_rating ~ best_actor_win + best_actress_win + 
    audience_score + critics_score, data = movies2)
print('runtime')
print(summary(m4)$adj.r.squared)

m5 = lm(imdb_rating ~ best_actor_win + best_actress_win + 
    audience_score + runtime, data = movies2)
print('critics_score')
print(summary(m5)$adj.r.squared)
```

On this iteration, it makes sense to drop the `best_actor_win` variable as it gives us the biggest `adjusted R^2` gains.

```{r}
m0 = lm(imdb_rating ~ best_actress_win + 
    audience_score + runtime + critics_score, data = movies2)
print('initial')
print(summary(m0)$adj.r.squared)

m1 = lm(imdb_rating ~ audience_score + runtime + critics_score, data = movies2)
print('best_actress_win')
print(summary(m1)$adj.r.squared)

m2 = lm(imdb_rating ~ best_actress_win + 
     runtime + critics_score, data = movies2)
print('audience_score')
print(summary(m2)$adj.r.squared)

m3 = lm(imdb_rating ~ best_actress_win + 
    audience_score + critics_score, data = movies2)
print('runtime')
print(summary(m3)$adj.r.squared)

m4 = lm(imdb_rating ~ best_actress_win + 
    audience_score + runtime, data = movies2)
print('critics_score')
print(summary(m4)$adj.r.squared)
```

On this iteration, dropping the `best_actress_win` variable will give us the biggest gains in `adjusted R^2` value.

```{r}
m0 = lm(imdb_rating ~ audience_score + runtime + critics_score, data = movies2)
print('initial')
print(summary(m0)$adj.r.squared)

m1 = lm(imdb_rating ~ runtime + critics_score, data = movies2)
print('audience_score')
print(summary(m1)$adj.r.squared)

m2 = lm(imdb_rating ~ audience_score + critics_score, data = movies2)
print('runtime')
print(summary(m2)$adj.r.squared)

m3 = lm(imdb_rating ~ audience_score + runtime, data = movies2)
print('critics_score')
print(summary(m3)$adj.r.squared)
```

Dropping any of the variables will not give us any improvements in `adjusted R^2` value so we stop iterating, our model is ready.

```{r}
summary(m0)
```

We can see that the `F-statistic` for the model is `895.3` on `3` and `646` degrees of freedom, such a large critical `F score` gives us nearly zero `p-value`(`<2.2e-16`) that agrees with model performance with such big `adjusted R^2` value (`0.8052`) which eventually means that at least one of the explanatory variable is a significant predictor of the response variable. At the same time, we can see that each of the variables have the tiny `p-values` which means that each of them is a significant predictor of the response(`imdb_rating`) variable given everything else held constant.

###### Interpritation of slopes

  - *audince_score*: With additional 1 point increase of `audience_score`, we would expect an increase in the `imdb_rating` score by `0.0340659` points on average, given everything else held constant.
  - *runtime*: With additional 1 point increase of `runtime`, we would expect increase in the `imdb_rating` score by
  `0.0056647` points on average, given everything else held constant.
  - *critics_score*: With additional 1 point increase of `critics_score`, we would expect an increase in the `imdb_rating` score by `0.0114496` points on average, given everything else held constant.
  
###### Confidence Intervals and Their Interpritation

We can compute CIs for the given parameters, as we can remember CIs are always `point estimate +- t*df * SE`.
We are given the `point estimate` and `SE`, we also know the sample size so can compute the critical t-score `t*df`.

`df = n - k - 1` - because we loose 1 degree of freedom for each predictor
`df = 651 - 3 - 1 = 647`

Knowing the `df` value, we can compute the critical `t-score`, since the degrees of freedom value is large, we would expect the t-distribution to be close to normal distribution thus close to `1.96` for `95% CI`.

```{r}
abs(qt(0.025, df = 647))
```
As expected the critical score value is very close to the `1.96`.

Now we can compute the CIs:

**audience_score**

```{r}
ME = abs(qt(0.025, df = 647)) * 0.0013129
b = 0.0340659
print(b - ME)
print(b + ME)
```

We are `95%` sure, that for each additional point in `audience_score`, the response variable, `imdb_rating` expected to be by `0.03148784` points larger to `0.03664396` points larger, given all else held constant. The result agreed with the `p-value` as the `CI` does not contain the `null-value` (`0`) which means we expected to reject the `null-hypothesis` given the CI alone.

**runtime**

```{r}
ME = abs(qt(0.025, df = 647)) * 0.0009848
b = 0.0056647
print(b - ME)
print(b + ME)
```

We are `95%` sure, that for each additional point in `audience_score`, the response variable, `imdb_rating` expected to be by `0.00373091` larger to `0.00759849` larger, given all else held constant.  The result agreed with the `p-value` as the `CI` does not contain the `null-value` (0) which means we expected to reject the `null-hypothesis` given the CI alone.

**critics_score**

```{r}
ME = abs(qt(0.025, df = 647)) * 0.0009336
b = 0.0114496
print(b - ME)
print(b + ME)
```

We are `95%` sure, that for each additional point in `audience_score`, the response variable, `imdb_rating` expected to be by `0.009616348` larger to `0.01328285` larger, given all else held constant.  The result agreed with the `p-value` as the `CI` does not contain the `null-value` (0) which means we expected to reject the `null-hypothesis` given the CI alone.

### Model Diagnostics

We need to perform model diagnostics to see if each of the variables conforms to the conditions needed for linear regression modeling.

#### Linearity

##### audience_score

> The relationship between `explanatory` and `response` variable should be `linear`.

For checking the linearity condition, we can fit a line to the scatterplot along with a residuals plot:

```{r}
ggplot(movies, aes(x = imdb_rating, y = audience_score)) + geom_jitter() + geom_smooth(method = "lm")

plot(m0$residuals ~ movies$audience_score) # linear assosiation = random scatter
```

We expect to see exactly random scatter around `0` to confirm the `linearity` condition, we can witness that the condition holds overall, there are some outliers at the bottom of the page but that should be ok as there are few of them.

##### runtime

For checking the linearity condition, we can fit a line to the scatterplot along with a residuals plot:

```{r}
ggplot(movies, aes(x = imdb_rating, y = runtime)) + geom_jitter() + geom_smooth(method = "lm")

plot(m0$residuals ~ movies$runtime) # linear assosiation = random scatter
```

We can confirm that the condition overall holds, the majority of observations clustered in a blob with the center in `0`, with some of the outliers at the bottom and at right of the blob.

##### critics_score

For checking the linearity condition, we can fit a line to the scatterplot along with a residuals plot:

```{r}
ggplot(movies, aes(x = imdb_rating, y = critics_score)) + geom_jitter() + geom_smooth(method = "lm")

plot(m0$residuals ~ movies$critics_score) # linear assosiation = random scatter
```

We can see that the condition holds overall with, there are some observations in the left bottom corner that must be clearly stated in reservations of the model.

##### Constant Variability

Let's check another condition for linear regression modeling - the `constant variability`, for that we will check plots of `residuals` vs their `fit values` as well as `absolute` value of the residuals vs their fit. If the `constant variability` condition holds we do not expect to see a fan shape on the plots:

```{r}
plot(m0$residuals ~ m0$fitted)
plot(abs(m0$residuals) ~ m0$fit)
```

On the first and the second plot we cannot see a clear trend in the data, the second plot does not contain any triangle which means there is no fan shape can be observed.

##### Nearly Normal Residuals

If the nearly normal residuals condition holds, we would see a nearly-normal unimodal symmetric distribution on residuals histogram, also we can check the `theoretical quantiles` to spot any deviations from the normality line:

```{r}
hist(md$residuals)

qqnorm(md$residuals); qqline(md$residuals)
```

We see a slight right skew in the histogram, but with such a big sample it might be totally fine. Looking at the theoretical quantiles plot we see few outliers at the higher end, while the deviation might be strong these are just a few observations so we can conclude that the condition holds with small reservations.

##### Independence

While we have a random sample which speaks to the independence of the residuals, let's plot the residuals to try to spot any pattern which will mean that we have time series observations(non-independence):

```{r}
plot(md$residuals)
```

The residuals plot looks totally fine, the data is randomly scattered around 0 without any obvious pattern - the condition of independence holds.

## Part 5: Prediction

Now we can pick a movie form the past to make a prediction. It is important to pick a movie that was released between 1970-2014, as otherwise, the prediction will imply `extrapolation` which will give us unreliable results.

Let's pick a ["The Lord of the Rings: The Two Towers (2002)"](https://www.rottentomatoes.com/m/the_lord_of_the_rings_the_two_towers) movie form the `Rotten Tomatoes`


```{r}
newdata = data.frame(audience_score=95, runtime = 180, critics_score = 96)
predict(m0, newdata, interval="predict")
```

So we are `95%` confident that the true `The Lord of the Rings: The Two Towers (2002)` movie rating on `IMDB` for audience score equal to 95%, with a runtime of `180 minutes` and critics score = 96% is `7.5` to `9.4` points.

Our model predicted the value to be `8.46` with the uncertainty interval above. If we will refer to the movie at the [IMDB](http://www.imdb.com/title/tt0167261/?ref_=nv_sr_3) site, we will see that the model slightly underestimates the rating, it is very close to the real observed value though, given that we use just 3 linear predictors:

`yhat = 8.463115`
`y = 8.7`
`residual = 8.7 - 8.46 = 0.24` => positive residual, model underestimates the rating score.

* * *

## Part 6: Conclusion

We have practiced the theoretical knowledge we gained during the course by conducting a research over the observational movies data sample that represents a random sample of 651 observations collected starting 1970 to up to 2014. We have analyzed the variables the data have and understood the correlation between them, found the variables that might be useful for building a `multivariate linear regression model` for predicting `idmb_rating` score with `audience_score`, `runtime` `critics_score` variables. For a sanity check, we took a new movie and successfully predicted its `idmb_rating`.

The most noticeable findings are:

- Reviewers on the `IMDB` tend to leave a good rating, there seem to be very little observations with ration less than 5.5 points.
- Reviewers on the `Rotten Tomatoes` though have more diverse opinions, the observations distribution was much more spread, the right end of the distribution was much closer to the higher end (100 scores).
- Surprisingly for the author, whether actor/actress or director have previously had a high valued regalia or not, the fact doesn't seem to have a significant correlation with the `IMDB` rating.
- Even a small amount of predictors can help to make a good predictive model - we had just 3 explanatory variables in the final model and the model performed pretty well, given that the methods we could use are constrained to linear ones only.
- Movie's runtime variable slightly improved the performance of the model which is not expected by the author.
- While `audience_score` and `critics_score` had a high correlation with each other which usually complicate model estimation, the model performance increased after including both variables.

### Reservations

The final regression model performed pretty well on a single "test" sample but it might not be true if we have had "sample" that contains multiple observations. While the movie was picked randomly, the good performance we observed might be simply due to chance - we should have a "multiple observations test sample" to test our model on for better understanding of model's performance.

When we made a model diagnostics, we allowed a couple of reservations:

- While the `audience_score` vs `imdb_rating` scatterplot look nearly linear, there is definitely a minor curvature on the plot, further examination of the fact could be done for determining what effect it can have on the study.
- During confirming independence condition, all 3 variable have some outliers present, there were just a few of them, but they definitely affect the model performance in the linear regression setting.
- Constant variability condition plot with absolute residuals have a set of outliers in the left top corner, 
which might speak to the shape of the distribution to be "fan out", while we don't believe that is the case, we need to exclude such possibility by conducting further investigation.
- The residuals normality could be checked in more detail, due to moderate skewness we have observed.
