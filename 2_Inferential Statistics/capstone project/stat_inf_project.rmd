---
title: "Statistical inference with the GSS data"
output: 
  html_document: 
    fig_height: 4
    highlight: pygments
    theme: spacelab
---

## Setup

### Load packages

```{r load-packages, message = FALSE}
library(ggplot2)
library(dplyr)
library(statsr)
```

### Load data

Make sure your data and R Markdown files are in the same directory. When loaded
your data file will be called `gss`. Delete this note when before you submit 
your work. 

```{r load-data}
load("gss.Rdata")
```

* * *

## Part 1: Data

  The data set represents an observational study - national sample gathered thru face-to-face interviews about 1.5 hours long. Each survey prior to 2004 was an independently drawn sample of English-speaking persons 18 y.o. or over, living in non-institutional arrangements within the United States. Starting in 2006 Spanish-speakers were added to the target population. Block quota sampling  and full probability sampling were employed in surveys of different years.
  The sample is a multi-stage area probability sample to the block or segment level. At the block level, however, quota sampling is used with quotas based on sex, age, and employment status.
  The Primary Sampling Units (PSUs) employed are Standard Metropolitan Statistical Areas (SMSAs) or non-metropolitan
counties selected in NORC's Master Sample. These SMSAs and counties were stratified by region, age, and race before selection.
  The chance of non-response bias was considered, so the interviewers are given instructions to canvass and interview only after 3:00 p.m. on weekdays or during the weekend or holidays. This type of sample design is most appropriate when the past experience and judgment of a project director suggest that sample biases are likely to be small relative to the precision of the measuring instrument and the decisions that are to be made.
  In addition to that, the `weighting` methods were applied, the GSS contains several weight variables (ADULTS, OVERSAMP, FORMWT, WTSSNR, WTSSALL) that users should use as needed as well as weight-related variables (ISSP+PHASE).
  Taking in the considereation all of the above (random sampling/clustering, blocking, stratifying, weighting, multi-stage probability sample, the bias encounting) we can state that the study is generalizable to the english- and spanish-speaking population of the US over 18 y.o. Because of the observational nature of the study, no random assigmnet was done so we can not conclude causality.

* * *

## Part 2: Research question

Does there appear to be a relationship between time spent in front of TV and job satisfaction level?

The question is of interest for author because he is interested in exploring how TV might potentually affect the other aspects of person's life. The author undestands that it is not possible to infer causation in the current study settings, so he only tries to find a relation between groups to understand if further analysis worths to be invested into.

* * *

## Part 3: Exploratory data analysis

Let's start with analyzing the hours spent in front of TV. Using samaries statistics and visualization, let's describe the distribution of TV hours:

```{r}
summary(gss$tvhours)
```

From the summary statistics we can see that the distribution is slightly right-skewed (because the `median` is smaller than the `mean`), alos we can witness that there is a natural boundery around `0` because watching negative number of hours does not make sense, hence we have the boundery at 0 with a long tail up to 24 hours period.

Let's visualize the data:

```{r}
ggplot(gss, aes(x = tvhours)) + geom_histogram(binwidth = 1)
```
The visualization conforms with our assumtions over moderate right skewness of the data. Now, for the sake of convinience, let's shrink number of the levels the variable has from 24 to 7:


```{r}

tvData <- gss %>% filter(!is.na(tvhours))

tvData <- tvData %>% mutate(tvhours7 = ifelse(tvhours == 0, '0 not watching',
                                              ifelse(tvhours >= 1 & tvhours <= 2, '1 some time',
                                                     ifelse(tvhours >= 3 & tvhours <= 4, '2 watching',
                                                        ifelse(tvhours >= 5 & tvhours <= 8, '3 watching a lot',
                                                            ifelse(tvhours >= 9 & tvhours <= 24, '4 all time', 'error')
                                                     )
                                              )
                                      )
                            )
)

tvData %>% group_by(tvhours7) %>% summarize(n = n())
```

As we can see we now have a ordinal categorical variable with 4 levels.

Let's explore the second variable in the same fashion, since the observations that have `NA` for TV hours spent are useless for our study, we will use the `tvData` data which we have ahd recently created. We will explore the `satjob` variable:

```{r}
summary(tvData$satjob)
```
We can see that this is an ordinal categorical variable with `4` levels. A lot of observations have `NA` values, since they are not helpful for our needs let's just filter them out:

```{r}
tvData <- tvData %>% filter(!is.na(satjob))

summary(tvData$satjob)
```
Now let's see the distributions of the categories:

```{r}
ggplot(tvData, aes(x = satjob)) + geom_bar()
```
We can see that the most people are satisfied with their jobs, the people that are dissatified with their jobs take less than 1/4 of the observations.

Let's transform the data to have only two levels of satisfaction for the convinience sake:

```{r}
tvData <- tvData %>% mutate(satjob2 = ifelse(satjob == 'Very Satisfied' | satjob == 'Mod. Satisfied', 'Satisfied', 'Not satisfied'))

tvData %>% group_by(satjob2) %>% summarize(n = n())
```


Now let's see the two variables on one scale, first let's build a `contingency table`:

```{r}
contincency <- table(tvData$satjob2, tvData$tvhours7)
contincency <- addmargins(contincency, 1)
contincency <- addmargins(contincency, 2)
print(contincency)
```

At the first glimpse we see that the data varies across the categories, let's build a stardintized barplot to try to catch the different in the categories proportions:

```{r}
ggplot(data = tvData, aes(x = satjob2, fill = tvhours7)) + geom_bar(position = "fill") +
  labs(title="Proportions who watch TV:") +
  xlab("job satisfaction") +
  ylab("amont of time spent in front of TV") +
  scale_fill_discrete(name = "How much TV is watching")
```
As we can see from the standartized barplot for levels proportions, the levels of `1 some time` and `3 watching a lot` have the most variation among the satisfaction levels. For the `1 some time` it is somewhat larger for the `Satisfied` level and is larger, at the same time the proportion of `3 watching a lot` is smaller for the `Satisfied` level and larger for the `Not satisfied` level. So our prior assumtion about the relation between the categories overall holds, so we can invest further into statistical inference methods to understand if this data provide a `statisticly significant` evidence that for the relation between the categories.

* * *

## Part 4: Inference

Let's do the inference, as we remember from the original research questions, we are intereseted if there appear to be a relationship between time spent in front of TV and job satisfaction level? Just finding a difference among the levels(and not knowing which levels exactly are different) is sufficient for our needs hence we can pick the `Chi-square independence` test to proceed. The test commonly used to determine whether there is a significant association between some two variables - exactly what we need here.

### First, let's state out hypotheses.

H0: Amount of TV watched per day and job satisfaction are independent, TV watching time habits job do not vary by job satisfaction.

Ha: Amount of TV watched per day and job satisfacgtion are dependen, TV watching time habits do vary by job satisfaction.

The `chi-square test of independence` in the nushell is:

- quantify how different the observed counts are from the expected counts
- large deviations from what would be expected on sampling variation(chance) alone provide strong evidence for the alternative hypothesis
- called independence test since we evaluate relationship between two categorical variables

### Now, let's check the conditions needed for the chi-square test of independence

1. Independence
  - random sample - the randomsampling techniques applied while data collected (random sampling/clustering, stratifying,multi-stage probability sampling, see Part1 fro more details)
  - sampling without replacement, and sample size of 57061 is much smaller than 10% of the entire population
  - each case contributes only to one cell in the contingency table - there is no human can watch tv 2 hours and 0 hours per day on average simultaneously, same for the job satisfaction levels as they are mutually exclusive too.
2. Sample size/skew
  - at least 5 expected cases for each cell
  
To test the last `condition` (at least 5 expected cases for each cell) let's estimate the number of expected counts for each cell of the contincency table, as we remember, the folmular is `((total # in column) * (total # in row)) / (total #)`


```{r}

nRows <- nrow(contincency)
nColumns <- ncol(contincency)
total <- contincency[nRows, nColumns]

contincencyExpected <- contincency[1:nRows, 1:nColumns]

for (i in 1:(nRows-1)) {
  for (j in 1:(nColumns-1)) {
    cell <- contincency[i, j]
    rowTotal = contincency[nRows, j]
    columnTotal = contincency[i, nColumns]
    contincencyExpected[i, j] <- round((rowTotal * columnTotal) / total)
  }
}

print(contincency)
print(contincencyExpected)
```
Having the `observed` and `expected` tables allows us to calculate the `Xsqaured` score, the formular is:

```{}
Xsquared = Sum( (O[i] - E[i])^2 / E[i] )
df = (# of rows - 1) * (# of columns - 1)
```

Let's calculate the values:

```{r}
df = ((nRows - 1) - 1) * ((nColumns - 1) - 1)

XSquared = 0
for (i in 1:(nRows-1)) {
  for (j in 1:(nColumns-1)) {
    cellO <- contincency[i, j]
    cellE <- contincencyExpected[i, j]
    XSquared = XSquared + (((cellO - cellE)^2) / cellE)
  }
}

print(df)
print(XSquared)
```

Finally we can calculate the `p-value`:

```{r}
p <- pchisq(XSquared, df = df, lower.tail = FALSE)
print(p)
```

With such a small `p-value` we will `reject the null-hypothesis` and conclude that the data provides significant evidence that indeed the TV watching time habits and job satisfaction are associated. 

As a sanity check, let's leverage the `inference` function and see if gives us the same results, for that we will use the `chisq.test` function and pass new contingency table without margins into it:

```{r}
chisq.test(table(tvData$satjob2, tvData$tvhours7))
```

As we can see the test statistics and all other parameters are almost equal to what we had, so it converged to the same results. Remember that this is an observational study so no causial relation can be inferred based on this, we can only say about the variables relation here.

To uderstand the actuall differences about to levels we can compare each TV watching time level by job satisfaction with other, reulsting in `(k * (k - 1)) / 2` total comparations:




